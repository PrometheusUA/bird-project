{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 14:34:29 INFO mlflow.utils.credentials: No valid Databricks credentials found, please enter your credentials...\n",
      "2024/06/09 14:34:44 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://community.cloud.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "mlflow.login(\"databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(\"/Users/shevtsov.pn@ucu.edu.ua/check-databricks-ce-connection\")\n",
    "\n",
    "# with mlflow.start_run():\n",
    "\n",
    "#     mlflow.log_metric(\"foo\", 1)\n",
    "\n",
    "#     mlflow.log_metric(\"bar\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from ml_base.model import BaselineBirdClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = os.path.realpath('../data/train_data_s3/')\n",
    "MODEL_SAVE_PATH = os.path.realpath('../data/models')\n",
    "VAL_FRAC = 0.1\n",
    "BATCH_SIZE = 16\n",
    "SAMPLE_LEN_SEC = 10\n",
    "SAMPLE_RATE = 32000\n",
    "EPOCHS_COUNT = 2\n",
    "EVAL_EVERY_STEPS = 20\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob(os.path.join(TRAIN_DATA_PATH, '**/*.ogg'))\n",
    "\n",
    "all_df = pd.DataFrame({'file_path': all_files})\n",
    "all_df['class'] = all_df['file_path'].apply(lambda filepath: os.path.basename(os.path.dirname(filepath)))\n",
    "\n",
    "CLASS2ID = {classname: i for i, classname in enumerate(all_df['class'].unique())}\n",
    "ID2CLASS = {i: classname for classname, i in CLASS2ID.items()}\n",
    "\n",
    "all_df['class_id'] = all_df['class'].apply(CLASS2ID.get)\n",
    "\n",
    "val_df = all_df.sample(int(VAL_FRAC * len(all_df)))\n",
    "train_df = all_df.loc[~all_df.index.isin(val_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, paths, labels=None, sample_len=SAMPLE_LEN_SEC, sr=SAMPLE_RATE):\n",
    "        assert labels is None or len(paths) == len(labels), \"Data and targets should be of the same samples count\"\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.sample_len = sample_len\n",
    "        self.sr = sr\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        audio, sr = librosa.load(self.paths[i], sr=self.sr)\n",
    "\n",
    "        if self.sample_len is not None:\n",
    "            desired_len = self.sample_len * sr\n",
    "            if len(audio) >desired_len:\n",
    "                audio = audio[:desired_len]\n",
    "            else:\n",
    "                audio =  np.pad(audio, (0, desired_len - len(audio)))\n",
    "\n",
    "        if self.labels is not None:\n",
    "            return audio, self.labels[i]\n",
    "        else:\n",
    "            return audio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = AudioDataset(train_df['file_path'].tolist(), train_df['class_id'].tolist())\n",
    "val_ds = AudioDataset(val_df['file_path'].tolist(), val_df['class_id'].tolist(), sample_len=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.0250 seconds\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = BaselineBirdClassifier(len(CLASS2ID), sr=SAMPLE_RATE).to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Node named 'test3' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAWS_SECRET_ACCESS_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3a6YbEfTeA21RswbKuHsR2j997stdup0180UoSmW\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m artifact_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://bird-project-artifacts/test2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/shevtsov.pn@ucu.edu.ua/test3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:1725\u001b[0m, in \u001b[0;36mcreate_experiment\u001b[1;34m(name, artifact_location, tags)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[0;32m   1678\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1680\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1681\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;124;03m    Create an experiment.\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;124;03m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\tracking\\client.py:1284\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[1;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[0;32m   1233\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1234\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1235\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1237\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \n\u001b[0;32m   1240\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:498\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[1;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m \n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    497\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[1;32m--> 498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mExperimentTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:122\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[1;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[0;32m    118\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    119\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m    120\u001b[0m     CreateExperiment(name\u001b[38;5;241m=\u001b[39mname, artifact_location\u001b[38;5;241m=\u001b[39martifact_location, tags\u001b[38;5;241m=\u001b[39mtag_protos)\n\u001b[0;32m    121\u001b[0m )\n\u001b[1;32m--> 122\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateExperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mexperiment_id\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:81\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body, endpoint)\u001b[0m\n\u001b[0;32m     79\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m     80\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:304\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[0;32m    301\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[0;32m    302\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[1;32m--> 304\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    306\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[1;32me:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:174\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[1;34m(response, endpoint)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[1;32m--> 174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m         )\n",
      "\u001b[1;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Node named 'test3' already exists"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = ''\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = ''\n",
    "\n",
    "artifact_uri = f\"s3://bird-project-artifacts/test2\"\n",
    "\n",
    "mlflow.create_experiment(\"/Users/shevtsov.pn@ucu.edu.ua/test3\", artifact_location=artifact_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20. Loss: 5.003870. Val loss: 5.005724.\n",
      "Saving the model\n",
      "labels=array([120,  38,  46,   4,  61,   2,  16,  54,  72,  36, 115,  61,  68,\n",
      "         8,  46,  86,   6,  51,  90,  63,  13,  17, 148,  67,  68, 120,\n",
      "       111,  17,  61,  67, 148,   8, 113,  21,  67,  63, 123, 108,  91,\n",
      "        93,  39, 107,  91,  62,  78, 134,  34,  59,  70,  48, 118,  36,\n",
      "        25,  72, 123,  90,  90,  48,  93,  34,  34,  44, 100,  13,  70,\n",
      "        72,  12, 113,  33,  64,  67,  95, 113,  33,  64,  64,   5, 148,\n",
      "        13,  51,  39,  68,  86,  35, 119, 121,  56,  68,  71,  85,  91,\n",
      "       121, 119,  32,   4,  54,  72, 120,  12, 146,  46,  46], dtype=int64), softmax(outputs)[0]=array([0.00636793, 0.00658233, 0.00667149, 0.00631394, 0.00666545,\n",
      "       0.00657114, 0.00694311, 0.00626425, 0.00706255, 0.0070194 ,\n",
      "       0.00714848, 0.00671908, 0.00687607, 0.0069673 , 0.00689273,\n",
      "       0.0069852 , 0.0066798 , 0.00702383, 0.0065198 , 0.00641801,\n",
      "       0.00690161, 0.00700131, 0.00659009, 0.0069406 , 0.00688632,\n",
      "       0.00636448, 0.00637756, 0.00680032, 0.00685337, 0.0068398 ,\n",
      "       0.00647959, 0.0066282 , 0.00666665, 0.00707307, 0.00656323,\n",
      "       0.00702529, 0.00632253, 0.00637632, 0.00690586, 0.00651079,\n",
      "       0.0068841 , 0.00666256, 0.00698367, 0.00647023, 0.00655648,\n",
      "       0.00671582, 0.00710491, 0.00686358, 0.00676086, 0.00647138,\n",
      "       0.00702234, 0.0068771 , 0.00692081, 0.00664396, 0.00665894,\n",
      "       0.00663629, 0.00688025, 0.00664633, 0.00682593, 0.00636587,\n",
      "       0.00648101, 0.0065676 , 0.00665606, 0.00682246, 0.0065272 ,\n",
      "       0.00676013, 0.00679912, 0.00684186, 0.00701935, 0.00633975,\n",
      "       0.00630203, 0.00673668, 0.00667154, 0.00692154, 0.00652098,\n",
      "       0.00701981, 0.00702871, 0.00658754, 0.00665933, 0.00676192,\n",
      "       0.00654561, 0.00660831, 0.0066347 , 0.00678265, 0.00696629,\n",
      "       0.00693272, 0.00630567, 0.00689496, 0.00684778, 0.00711371,\n",
      "       0.00641911, 0.00650868, 0.00632689, 0.00696044, 0.00691286,\n",
      "       0.0067089 , 0.00699355, 0.0066983 , 0.00699963, 0.00682441,\n",
      "       0.00703103, 0.00633857, 0.0067022 , 0.00700471, 0.00661101,\n",
      "       0.00679279, 0.00633694, 0.0066072 , 0.00635642, 0.00656921,\n",
      "       0.00641128, 0.00669625, 0.00702438, 0.00640768, 0.00708084,\n",
      "       0.00650884, 0.00712506, 0.00679852, 0.00669735, 0.00641868,\n",
      "       0.00677241, 0.0068898 , 0.00630725, 0.00689422, 0.0069357 ,\n",
      "       0.00633138, 0.00647671, 0.00629356, 0.00711352, 0.00650603,\n",
      "       0.0070416 , 0.0066776 , 0.00692401, 0.00679146, 0.00639509,\n",
      "       0.0067371 , 0.00663092, 0.00628126, 0.0067456 , 0.00633989,\n",
      "       0.00688796, 0.00691117, 0.00705654, 0.00644864, 0.00663455,\n",
      "       0.00694417, 0.00652313, 0.00690103, 0.00632856], dtype=float32)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148]\n",
      "Batch 40. Loss: 5.005026. Val loss: 5.005143.\n",
      "Saving the model\n",
      "labels=array([120,  38,  46,   4,  61,   2,  16,  54,  72,  36, 115,  61,  68,\n",
      "         8,  46,  86,   6,  51,  90,  63,  13,  17, 148,  67,  68, 120,\n",
      "       111,  17,  61,  67, 148,   8, 113,  21,  67,  63, 123, 108,  91,\n",
      "        93,  39, 107,  91,  62,  78, 134,  34,  59,  70,  48, 118,  36,\n",
      "        25,  72, 123,  90,  90,  48,  93,  34,  34,  44, 100,  13,  70,\n",
      "        72,  12, 113,  33,  64,  67,  95, 113,  33,  64,  64,   5, 148,\n",
      "        13,  51,  39,  68,  86,  35, 119, 121,  56,  68,  71,  85,  91,\n",
      "       121, 119,  32,   4,  54,  72, 120,  12, 146,  46,  46], dtype=int64), softmax(outputs)[0]=array([0.006359  , 0.0065873 , 0.00667169, 0.00631151, 0.00666885,\n",
      "       0.00656657, 0.00693841, 0.00625421, 0.00706373, 0.00701444,\n",
      "       0.00715335, 0.00672171, 0.00687158, 0.00697306, 0.00688761,\n",
      "       0.00697325, 0.00669021, 0.00702403, 0.00651428, 0.00641394,\n",
      "       0.00689484, 0.00698816, 0.00659209, 0.00693985, 0.00687887,\n",
      "       0.00636481, 0.00637118, 0.00679991, 0.00684083, 0.00685127,\n",
      "       0.00648582, 0.00661607, 0.00666274, 0.0070763 , 0.00658029,\n",
      "       0.0070273 , 0.00633193, 0.00638612, 0.00690014, 0.00651086,\n",
      "       0.00688427, 0.00666938, 0.0069862 , 0.00646425, 0.00656792,\n",
      "       0.00670368, 0.00710584, 0.0068744 , 0.00677146, 0.00647652,\n",
      "       0.00702894, 0.00686695, 0.00693294, 0.00665405, 0.00666891,\n",
      "       0.00664027, 0.00688569, 0.00664961, 0.0068143 , 0.0063692 ,\n",
      "       0.00648064, 0.00656244, 0.00665285, 0.00681219, 0.00653289,\n",
      "       0.00674693, 0.0067981 , 0.00685339, 0.00703409, 0.00633028,\n",
      "       0.00631435, 0.00674753, 0.00666435, 0.00692427, 0.00652474,\n",
      "       0.00701819, 0.00703153, 0.00658772, 0.00665181, 0.00675338,\n",
      "       0.00653933, 0.00660904, 0.00663493, 0.00678241, 0.00695454,\n",
      "       0.00693913, 0.00631058, 0.00689081, 0.00684801, 0.00711122,\n",
      "       0.00642624, 0.00650676, 0.00633691, 0.00696431, 0.00691664,\n",
      "       0.00671744, 0.00698886, 0.00668373, 0.00701096, 0.00682037,\n",
      "       0.00704068, 0.00633597, 0.0066966 , 0.00701603, 0.00661112,\n",
      "       0.00679595, 0.00633389, 0.00660136, 0.00635469, 0.00657313,\n",
      "       0.00640216, 0.00669609, 0.00702864, 0.00640553, 0.00707109,\n",
      "       0.00651056, 0.00711392, 0.0068061 , 0.00670167, 0.00641875,\n",
      "       0.00678906, 0.00688743, 0.00630421, 0.00688967, 0.00693254,\n",
      "       0.00632569, 0.00647566, 0.00629093, 0.00710757, 0.00649754,\n",
      "       0.00704108, 0.00667967, 0.00692051, 0.00678684, 0.00637652,\n",
      "       0.0067281 , 0.00664504, 0.00629361, 0.00673858, 0.00632682,\n",
      "       0.00689045, 0.00690712, 0.00704867, 0.00645055, 0.00664366,\n",
      "       0.00694782, 0.00653482, 0.00689755, 0.00634164], dtype=float32)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [00:54<00:54, 54.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60. Loss: 0.500447. Val loss: 5.004598.\n",
      "Saving the model\n",
      "labels=array([120,  38,  46,   4,  61,   2,  16,  54,  72,  36, 115,  61,  68,\n",
      "         8,  46,  86,   6,  51,  90,  63,  13,  17, 148,  67,  68, 120,\n",
      "       111,  17,  61,  67, 148,   8, 113,  21,  67,  63, 123, 108,  91,\n",
      "        93,  39, 107,  91,  62,  78, 134,  34,  59,  70,  48, 118,  36,\n",
      "        25,  72, 123,  90,  90,  48,  93,  34,  34,  44, 100,  13,  70,\n",
      "        72,  12, 113,  33,  64,  67,  95, 113,  33,  64,  64,   5, 148,\n",
      "        13,  51,  39,  68,  86,  35, 119, 121,  56,  68,  71,  85,  91,\n",
      "       121, 119,  32,   4,  54,  72, 120,  12, 146,  46,  46], dtype=int64), softmax(outputs)[0]=array([0.00636045, 0.00657959, 0.00666862, 0.00630538, 0.00667165,\n",
      "       0.00655599, 0.00693749, 0.00624224, 0.00705813, 0.00701659,\n",
      "       0.00715256, 0.00672537, 0.00687988, 0.00696962, 0.00687528,\n",
      "       0.00697037, 0.00669463, 0.0070204 , 0.0065125 , 0.00640585,\n",
      "       0.0068904 , 0.00697492, 0.00660059, 0.00694855, 0.00687769,\n",
      "       0.00636697, 0.00637003, 0.00679649, 0.00684063, 0.0068548 ,\n",
      "       0.00648989, 0.00660677, 0.00666117, 0.00707937, 0.00659397,\n",
      "       0.00703125, 0.0063366 , 0.00638657, 0.00690044, 0.00651077,\n",
      "       0.00688531, 0.00667442, 0.00699209, 0.006463  , 0.00657555,\n",
      "       0.00669509, 0.00711544, 0.0068678 , 0.00678021, 0.00648569,\n",
      "       0.0070264 , 0.00685587, 0.00693465, 0.00666308, 0.00668427,\n",
      "       0.00664829, 0.00689285, 0.00664741, 0.00681507, 0.00636996,\n",
      "       0.00648141, 0.00656641, 0.00664666, 0.00681439, 0.00654294,\n",
      "       0.0067377 , 0.00679747, 0.00686297, 0.00703982, 0.00632166,\n",
      "       0.00631875, 0.00674539, 0.0066644 , 0.00691329, 0.00651907,\n",
      "       0.00702195, 0.00703599, 0.00658544, 0.00664309, 0.00675299,\n",
      "       0.00653189, 0.00661126, 0.00663327, 0.00678555, 0.00694078,\n",
      "       0.00693662, 0.00632132, 0.00689835, 0.00684753, 0.00711149,\n",
      "       0.00643715, 0.00650636, 0.00633868, 0.00696842, 0.00692468,\n",
      "       0.00672183, 0.00699282, 0.00667537, 0.00701527, 0.00682301,\n",
      "       0.00704399, 0.00633803, 0.0066935 , 0.00701944, 0.00661639,\n",
      "       0.00678692, 0.006326  , 0.00659516, 0.00636126, 0.00657733,\n",
      "       0.00639937, 0.00669806, 0.00701975, 0.00640459, 0.00706684,\n",
      "       0.00650661, 0.0071154 , 0.00680543, 0.00671409, 0.00641962,\n",
      "       0.00680257, 0.00688672, 0.00629946, 0.00687962, 0.00692742,\n",
      "       0.0063197 , 0.00647918, 0.00629279, 0.00710351, 0.00649861,\n",
      "       0.00703151, 0.00667886, 0.00692258, 0.006776  , 0.00636271,\n",
      "       0.00672056, 0.00664946, 0.00629636, 0.00673438, 0.00631927,\n",
      "       0.00688971, 0.00691135, 0.00704119, 0.0064525 , 0.00664369,\n",
      "       0.00695506, 0.00654204, 0.00689292, 0.00635621], dtype=float32)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148]\n",
      "Batch 80. Loss: 5.004671. Val loss: 5.003897.\n",
      "Saving the model\n",
      "labels=array([120,  38,  46,   4,  61,   2,  16,  54,  72,  36, 115,  61,  68,\n",
      "         8,  46,  86,   6,  51,  90,  63,  13,  17, 148,  67,  68, 120,\n",
      "       111,  17,  61,  67, 148,   8, 113,  21,  67,  63, 123, 108,  91,\n",
      "        93,  39, 107,  91,  62,  78, 134,  34,  59,  70,  48, 118,  36,\n",
      "        25,  72, 123,  90,  90,  48,  93,  34,  34,  44, 100,  13,  70,\n",
      "        72,  12, 113,  33,  64,  67,  95, 113,  33,  64,  64,   5, 148,\n",
      "        13,  51,  39,  68,  86,  35, 119, 121,  56,  68,  71,  85,  91,\n",
      "       121, 119,  32,   4,  54,  72, 120,  12, 146,  46,  46], dtype=int64), softmax(outputs)[0]=array([0.00636424, 0.00655633, 0.00666986, 0.00629199, 0.00667561,\n",
      "       0.0065365 , 0.00693497, 0.00622876, 0.00704312, 0.00702706,\n",
      "       0.00714809, 0.00673057, 0.00690162, 0.00696666, 0.00686478,\n",
      "       0.00697121, 0.00670229, 0.00701241, 0.0065009 , 0.00639467,\n",
      "       0.00688695, 0.00696229, 0.00661679, 0.00696816, 0.00688163,\n",
      "       0.00636933, 0.0063777 , 0.00678771, 0.00684215, 0.00685599,\n",
      "       0.0065018 , 0.00659314, 0.00665929, 0.0070804 , 0.00660952,\n",
      "       0.00703681, 0.00634396, 0.0063856 , 0.00690035, 0.00651376,\n",
      "       0.0068836 , 0.00668239, 0.00699568, 0.00646776, 0.00657394,\n",
      "       0.00668192, 0.00713033, 0.00684703, 0.00679947, 0.00649957,\n",
      "       0.00701928, 0.00684334, 0.00693054, 0.00667651, 0.00670788,\n",
      "       0.00665896, 0.00689497, 0.00663806, 0.00682311, 0.00636432,\n",
      "       0.00647918, 0.00657584, 0.00663589, 0.00682294, 0.00656109,\n",
      "       0.00672258, 0.00679216, 0.00687355, 0.00704353, 0.00631519,\n",
      "       0.00631884, 0.00673107, 0.00667459, 0.0068832 , 0.0065039 ,\n",
      "       0.00702943, 0.00704759, 0.00658324, 0.00663509, 0.00675573,\n",
      "       0.00652008, 0.00662325, 0.0066236 , 0.00678723, 0.00692222,\n",
      "       0.00693112, 0.00634165, 0.0069184 , 0.00685219, 0.00710705,\n",
      "       0.00645073, 0.0065044 , 0.0063319 , 0.00696629, 0.00693326,\n",
      "       0.00672451, 0.00701135, 0.00666878, 0.00702064, 0.00683444,\n",
      "       0.00704058, 0.00634297, 0.00669439, 0.00702083, 0.00663145,\n",
      "       0.00677277, 0.00631823, 0.00658703, 0.00637089, 0.00657573,\n",
      "       0.00639741, 0.00670784, 0.00699888, 0.00640733, 0.0070636 ,\n",
      "       0.00649881, 0.0071287 , 0.0067983 , 0.00673566, 0.00642659,\n",
      "       0.00682178, 0.00688529, 0.00629131, 0.00685913, 0.00691421,\n",
      "       0.00631777, 0.00649145, 0.00629765, 0.00708899, 0.00650326,\n",
      "       0.0070084 , 0.00667403, 0.00693428, 0.0067625 , 0.00634698,\n",
      "       0.00671484, 0.00664574, 0.00629646, 0.00673799, 0.00630762,\n",
      "       0.00688483, 0.00691598, 0.0070315 , 0.00645773, 0.00664309,\n",
      "       0.00696907, 0.00654424, 0.00689252, 0.00637202], dtype=float32)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148]\n",
      "Batch 100. Loss: 5.002259. Val loss: 5.002925.\n",
      "Saving the model\n",
      "labels=array([120,  38,  46,   4,  61,   2,  16,  54,  72,  36, 115,  61,  68,\n",
      "         8,  46,  86,   6,  51,  90,  63,  13,  17, 148,  67,  68, 120,\n",
      "       111,  17,  61,  67, 148,   8, 113,  21,  67,  63, 123, 108,  91,\n",
      "        93,  39, 107,  91,  62,  78, 134,  34,  59,  70,  48, 118,  36,\n",
      "        25,  72, 123,  90,  90,  48,  93,  34,  34,  44, 100,  13,  70,\n",
      "        72,  12, 113,  33,  64,  67,  95, 113,  33,  64,  64,   5, 148,\n",
      "        13,  51,  39,  68,  86,  35, 119, 121,  56,  68,  71,  85,  91,\n",
      "       121, 119,  32,   4,  54,  72, 120,  12, 146,  46,  46], dtype=int64), softmax(outputs)[0]=array([0.00635887, 0.00653884, 0.00666679, 0.00627663, 0.00668582,\n",
      "       0.00651454, 0.00692718, 0.0062137 , 0.00703372, 0.00703199,\n",
      "       0.00713805, 0.00673263, 0.00691664, 0.00696902, 0.00685765,\n",
      "       0.00696291, 0.00672452, 0.00701528, 0.00648202, 0.00638464,\n",
      "       0.00688828, 0.00694349, 0.00662865, 0.00698112, 0.00688048,\n",
      "       0.00636992, 0.00637911, 0.00677268, 0.0068395 , 0.00685081,\n",
      "       0.00652195, 0.00657968, 0.00665386, 0.00707936, 0.00663678,\n",
      "       0.00703902, 0.0063579 , 0.0063887 , 0.00689389, 0.00652151,\n",
      "       0.0068875 , 0.00670278, 0.00700151, 0.00647921, 0.00658364,\n",
      "       0.0066633 , 0.00714745, 0.00683933, 0.00683011, 0.00650584,\n",
      "       0.00702683, 0.00682958, 0.00692749, 0.00668715, 0.00673403,\n",
      "       0.00666667, 0.00690023, 0.00663605, 0.00682495, 0.00635606,\n",
      "       0.00646944, 0.0065714 , 0.0066286 , 0.00683034, 0.00657918,\n",
      "       0.00669172, 0.00679761, 0.00689775, 0.00705377, 0.00630362,\n",
      "       0.00632318, 0.0067348 , 0.00667675, 0.00686142, 0.00650454,\n",
      "       0.00703422, 0.00705688, 0.0065724 , 0.00662518, 0.00674959,\n",
      "       0.00649771, 0.00663857, 0.0066188 , 0.00678233, 0.00691138,\n",
      "       0.00693147, 0.00635584, 0.00692389, 0.00686029, 0.00709798,\n",
      "       0.00646285, 0.00650313, 0.00633904, 0.00695822, 0.00695626,\n",
      "       0.00674069, 0.00702573, 0.00664615, 0.00701968, 0.00684122,\n",
      "       0.00704572, 0.00634173, 0.0067003 , 0.00704019, 0.00663944,\n",
      "       0.00676575, 0.00630626, 0.00657607, 0.0063757 , 0.00656648,\n",
      "       0.00639437, 0.00672125, 0.00697581, 0.00641746, 0.00706026,\n",
      "       0.00650143, 0.00713034, 0.00679704, 0.00675837, 0.00643725,\n",
      "       0.00684338, 0.00687165, 0.00627217, 0.00682822, 0.00689918,\n",
      "       0.00630825, 0.00649816, 0.00629576, 0.00707882, 0.00650035,\n",
      "       0.00699179, 0.00666355, 0.00694022, 0.00674484, 0.00632104,\n",
      "       0.00670115, 0.00665421, 0.00630959, 0.0067369 , 0.00628087,\n",
      "       0.00688735, 0.00691991, 0.00702004, 0.00647191, 0.00665978,\n",
      "       0.00698701, 0.00654934, 0.00688806, 0.0063838 ], dtype=float32)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [01:59<00:00, 59.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to ONNX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\nnAudio\\features\\stft.py:283: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.num_samples < self.pad_amount:\n",
      "e:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\notebooks\\..\\ml_base\\model.py:28: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if return_spec:\n",
      "e:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "e:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4661: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "e:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "e:\\_UNIVER\\UCU\\2 sem\\MLOps\\bird-project\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:1208: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export finished\n",
      "ONNX model checked\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Users/shevtsov.pn@ucu.edu.ua/test2\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    mlflow.log_params({\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs_count\": EPOCHS_COUNT,\n",
    "        \"sample_rate\": SAMPLE_RATE\n",
    "    })\n",
    "\n",
    "    batch_num = 0\n",
    "\n",
    "    min_eval_loss = np.inf\n",
    "    corresp_train_loss = np.inf\n",
    "    best_loss_metrics = None\n",
    "\n",
    "    training_start_time = time()\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS_COUNT), desc='Epoch'):\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "\n",
    "        for audios, labels in train_loader:\n",
    "            audios = audios.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(audios)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch_num % EVAL_EVERY_STEPS == EVAL_EVERY_STEPS - 1:\n",
    "                last_loss = running_loss / EVAL_EVERY_STEPS\n",
    "                print(f'Batch {batch_num + 1}. Loss: {last_loss:.6f}.', end=' ')\n",
    "                running_loss = 0.\n",
    "\n",
    "                model.eval()\n",
    "                eval_running_loss = 0.\n",
    "                outputs_list = []\n",
    "                labels_list = []\n",
    "                with torch.no_grad():\n",
    "                    for audios, labels in val_loader:\n",
    "                        audios = audios.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        outputs = model(audios)\n",
    "                        loss = loss_fn(outputs, labels)\n",
    "\n",
    "                        eval_running_loss += loss.item()\n",
    "                        outputs_list.append(outputs.cpu().numpy())\n",
    "                        labels_list.append(labels.cpu().numpy())\n",
    "                \n",
    "                eval_running_loss = eval_running_loss/len(val_ds)\n",
    "\n",
    "                print(f'Val loss: {eval_running_loss:.6f}.')                \n",
    "\n",
    "                if eval_running_loss < min_eval_loss:\n",
    "                    min_eval_loss = eval_running_loss\n",
    "                    corresp_train_loss = last_loss\n",
    "                    print(\"Saving the model\")\n",
    "\n",
    "                    outputs = np.concatenate(outputs_list, axis=0)\n",
    "                    labels = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "                    accuracy = accuracy_score(labels, outputs.argmax(axis=1))\n",
    "                    f1 = f1_score(labels, outputs.argmax(axis=1), average='macro', zero_division=1)\n",
    "                    prec = precision_score(labels, outputs.argmax(axis=1), average='macro', zero_division=1)\n",
    "                    rec = recall_score(labels, outputs.argmax(axis=1), average='macro', zero_division=1)\n",
    "                    \n",
    "                    best_loss_metrics = {\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"macro_f1\": f1,\n",
    "                        \"macro_precision\": prec,\n",
    "                        \"macro_recall\": rec,\n",
    "                    }\n",
    "\n",
    "                    torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, f'baseline-{len(CLASS2ID)}.pt'))\n",
    "\n",
    "                model.train()\n",
    "            batch_num += 1\n",
    "\n",
    "    mlflow.log_metric(\"train_time_sec\", time() - training_start_time)\n",
    "    mlflow.log_metric(\"min_val_loss\", min_eval_loss)\n",
    "    mlflow.log_metric(\"train_loss\", last_loss)\n",
    "    mlflow.log_metrics(best_loss_metrics)\n",
    "\n",
    "    print(\"Exporting to ONNX\")\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, f'baseline-{len(CLASS2ID)}.pt'), map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "\n",
    "    torch_input = torch.randn(8, SAMPLE_RATE*SAMPLE_LEN_SEC)\n",
    "    torch.onnx.export(model.cpu(),\n",
    "                    torch_input,\n",
    "                    os.path.join(MODEL_SAVE_PATH, f'baseline-{len(CLASS2ID)}.onnx'),\n",
    "                    export_params=True,\n",
    "                    do_constant_folding=True,\n",
    "                    input_names = ['input'],\n",
    "                    output_names = ['output'],\n",
    "                    dynamic_axes={'input' : {0: 'batch_size', 1: 'sample_length'},\n",
    "                                'output' : {0: 'batch_size'}}\n",
    "    )\n",
    "\n",
    "    print(\"ONNX export finished\")\n",
    "\n",
    "    onnx_model = onnx.load(os.path.join(MODEL_SAVE_PATH, f'baseline-{len(CLASS2ID)}.onnx'))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "    print(\"ONNX model checked\")\n",
    "\n",
    "    mlflow.log_artifact(os.path.join(MODEL_SAVE_PATH, f'baseline-{len(CLASS2ID)}.onnx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
